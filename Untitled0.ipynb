{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsQ4aVMywXFqaR8qo/whgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c80c197c2a94c61b07a5faec2fb5ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee03ebac9a94037ba3c3de74789f8b2",
              "IPY_MODEL_021bed601d14444b973758c55713b932",
              "IPY_MODEL_d7dc8e9cf4384a15b3ce060f98037276"
            ],
            "layout": "IPY_MODEL_ce51112fc0794af5be960fc840f6620e"
          }
        },
        "eee03ebac9a94037ba3c3de74789f8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9518e967264c4aa4acdc6c7a30b2c5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_6e314e3ca1ac4725a414a4090e3ace5e",
            "value": "Making predictions: 100%"
          }
        },
        "021bed601d14444b973758c55713b932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b948c76fa7c3485a9e41d15f86bdf5b7",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b885ec5c2aea46f9ae905fa97cc5d6b9",
            "value": 313
          }
        },
        "d7dc8e9cf4384a15b3ce060f98037276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82913edb5439430fa3d9edf21337f8e2",
            "placeholder": "​",
            "style": "IPY_MODEL_1c6a9489c92b482ba393e35756b190e0",
            "value": " 313/313 [00:01&lt;00:00, 293.75it/s]"
          }
        },
        "ce51112fc0794af5be960fc840f6620e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9518e967264c4aa4acdc6c7a30b2c5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e314e3ca1ac4725a414a4090e3ace5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b948c76fa7c3485a9e41d15f86bdf5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b885ec5c2aea46f9ae905fa97cc5d6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82913edb5439430fa3d9edf21337f8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6a9489c92b482ba393e35756b190e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Squirrelcoding/learn-pytorch-io/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttc1Xny7-0lq",
        "outputId": "6e9394fc-8de5-4734-ba42-eb13ec0fe7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 0 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 12800 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 25600 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 38400 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 51200 /60000 samples\n",
            "Train loss: 0.3868333399295807, Train accuracy: 86.55333333333333 | Test loss: 0.08222362399101257, Test accuracy97.32428115015975\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 0 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 12800 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 25600 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 38400 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 51200 /60000 samples\n",
            "Train loss: 0.07321379333734512, Train accuracy: 97.72666666666667 | Test loss: 0.05093871057033539, Test accuracy98.23282747603834\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 0 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 12800 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 25600 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 38400 /60000 samples\n",
            "torch.Size([32, 1, 28, 28])\n",
            "Looked at 51200 /60000 samples\n",
            "Train loss: 0.05574789643287659, Train accuracy: 98.32333333333334 | Test loss: 0.04035445302724838, Test accuracy98.66214057507987\n",
            "Saving model to: models/mnist.pth\n"
          ]
        }
      ],
      "source": [
        "# import pytorch stuff\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# import torchvision stuff\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        ")\n",
        "\n",
        "class_names = train_data.classes\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MNISTModel(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(X.shape)\n",
        "            print(f\"Looked at {batch * len(X)} /{len(train_dataloader.dataset)} samples\") #pyright: ignore\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_acc /= len(train_dataloader)\n",
        "\n",
        "    # Testing!!!\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            test_pred = model(X)\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    print(f\"Train loss: {train_loss}, Train accuracy: {train_acc} | Test loss: {test_loss}, Test accuracy{test_acc}\")\n",
        "\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = \"mnist.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
        "           f=MODEL_SAVE_PATH)\n",
        "\n",
        "# Visualize some predictions!!!\n",
        "\n",
        "# fig = plt.figure(figsize=(9, 9))\n",
        "# rows, cols = 4, 4\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "# with torch.inference_mode():\n",
        "#     for i in range(1, rows * cols + 1):\n",
        "#         random_idx = torch.randint(0, len(test_data), size=[1]).item()\n",
        "#         img, label = test_dataloader.dataset[random_idx] #pyright: ignore\n",
        "\n",
        "#         img = torch.unsqueeze(img, dim=0).to(device)\n",
        "\n",
        "#         test_pred = model(img).argmax(dim=1)[0]\n",
        "#         print(test_pred)\n",
        "\n",
        "\n",
        "#         fig.add_subplot(rows, cols, i)\n",
        "#         plt.imshow(img.cpu().squeeze(), cmap=\"gray\")\n",
        "#         plt.title(test_pred)\n",
        "#         plt.axis(False);\n",
        "\n",
        "#     plt.savefig('mnist_predictions.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iSVYcI9dBGft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the model"
      ],
      "metadata": {
        "id": "HYawc07pBHdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = MNISTModel(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 5, 5\n",
        "\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for i in range(1, rows * cols + 1):\n",
        "        img = torch.rand(1, 28, 28)\n",
        "\n",
        "        img = torch.unsqueeze(img, dim=0).to(device)\n",
        "\n",
        "        test_pred = loaded_model(img).argmax(dim=1)[0]\n",
        "        print(test_pred)\n",
        "\n",
        "\n",
        "        fig.add_subplot(rows, cols, i)\n",
        "        plt.imshow(img.cpu().squeeze(), cmap=\"gray\")\n",
        "        plt.title(test_pred.item())\n",
        "        plt.axis(False);\n",
        "\n",
        "    plt.savefig('predictions.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYM7Rh5bA1PT",
        "outputId": "08c2781f-b0ab-46a9-a95a-998c61a2c82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e7335160ddfd>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(8, device='cuda:0')\n",
            "tensor(5, device='cuda:0')\n",
            "tensor(5, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(5, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(5, device='cuda:0')\n",
            "tensor(8, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "import tqdm\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsyTTc4DC8u5",
        "outputId": "dc7f614b-45fa-4833-f245-b70fdbe352dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "loaded_model.eval()\n",
        "\n",
        "y_preds = []\n",
        "\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Do the forward pass\n",
        "    y_logit = loaded_model(X)\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0c80c197c2a94c61b07a5faec2fb5ed9",
            "eee03ebac9a94037ba3c3de74789f8b2",
            "021bed601d14444b973758c55713b932",
            "d7dc8e9cf4384a15b3ce060f98037276",
            "ce51112fc0794af5be960fc840f6620e",
            "9518e967264c4aa4acdc6c7a30b2c5ab",
            "6e314e3ca1ac4725a414a4090e3ace5e",
            "b948c76fa7c3485a9e41d15f86bdf5b7",
            "b885ec5c2aea46f9ae905fa97cc5d6b9",
            "82913edb5439430fa3d9edf21337f8e2",
            "1c6a9489c92b482ba393e35756b190e0"
          ]
        },
        "id": "B9l6UVESDVC9",
        "outputId": "60c50fb3-0147-4ba8-ba90-55648800be9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Making predictions:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c80c197c2a94c61b07a5faec2fb5ed9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPvPlCIGD82q",
        "outputId": "f1bd4349-bd5e-4f78-fd02-23496162c262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hmlxtend version: 0.23.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlxtend\n",
        "\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. Setup confusion matrix instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "\n",
        "# 3. Plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy\n",
        "    class_names=class_names, # turn the row and column labels into class names\n",
        "    figsize=(10, 7)\n",
        ");\n",
        "\n",
        "plt.savefig('predictions.png')"
      ],
      "metadata": {
        "id": "uLg66P83DmlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(1, 3, 64, 64)\n",
        "\n",
        "nn.Conv2d(in_channels=3, out_channels=10, kernel_size=4)(random_tensor).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVXGAodsFuNr",
        "outputId": "c63da9b2-8c1b-443d-c633-9d789e51af67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 61, 61])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Classification\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "H, W = 32, 32\n",
        "img = torch.randint(0, 256, size=(1, H, W), dtype=torch.uint8)\n",
        "\n",
        "transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Permute to (H, W, C) for displaying\n",
        "img = img.permute(1, 2, 0)\n",
        "\n",
        "# Normalize back to display correctly\n",
        "img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
        "img = img.clamp(0, 1)  # Ensure values are in valid range\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.savefig(\"example.png\")"
      ],
      "metadata": {
        "id": "rQWbNbAsICXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}